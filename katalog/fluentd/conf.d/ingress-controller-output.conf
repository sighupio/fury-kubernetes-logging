<filter kubernetes.var.log.containers.nginx-ingress-**.log>
  @type parser
  format /^(?<remote_addr>[^ ]*) - (?<remote_user>[^ ]+) \[(?<time_local>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*) +\S*)?" (?<status>\d+) (?<body_bytes_sent>\d+) "(?<http_referer>[^ ]*)" "(?<http_user_agent>[^\"]*)" (?<request_length>\d+) (?<request_time>[\d.]+) \[(?<proxy_upstream_name>[^\]]*)\] \[(?<proxy_alternative_upstream_name>[^\]]*)\] (?<upstream_addr>[^ ]*) (?<upstream_response_length>\d+) (?<upstream_response_time>[\d.]+) (?<upstream_status>\d+) (?<req_id>[^ ]*)/
  time_format %d/%b/%Y:%H:%M:%S %z
  key_name log
  types status:integer,body_bytes_sent:integer,request_length:integer,upstream_response_length:integer,upstream_response_time:float,upstream_status:integer
  reserve_data yes
</filter>
<filter kubernetes.var.log.containers.nginx-ingress-**.log>
  @type elasticsearch_genid
  hash_id_key _hash # storing generated hash id key (default is _hash)
</filter>
<match kubernetes.var.log.containers.nginx-ingress-**.log>
  @type copy
  <store>
     @type elasticsearch
     @id out_es_ingress
     @log_level "#{ENV['FLUENT_LOG_LEVEL'] || 'error'}"
     id_key _hash # specify same key name which is specified in hash_id_key
     remove_keys _hash # Elasticsearch doesn't like keys that start with _
     include_tag_key true
     host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
     port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
     path "#{ENV['FLUENT_ELASTICSEARCH_PATH']}"
     scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
     ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'true'}"
     ssl_version "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERSION'] || 'TLSv1_2'}"
     user "#{ENV['FLUENT_ELASTICSEARCH_USER'] || use_default}"
     password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD'] || use_default}"
     reload_connections "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_CONNECTIONS'] || 'false'}"
     reconnect_on_error "#{ENV['FLUENT_ELASTICSEARCH_RECONNECT_ON_ERROR'] || 'true'}"
     reload_on_failure "#{ENV['FLUENT_ELASTICSEARCH_RELOAD_ON_FAILURE'] || 'true'}"
     log_es_400_reason "#{ENV['FLUENT_ELASTICSEARCH_LOG_ES_400_REASON'] || 'true'}"
     logstash_prefix "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX_INGRESS'] || 'ingress-controller'}"
     logstash_dateformat "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_DATEFORMAT'] || '%Y.%m.%d'}"
     logstash_format "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_FORMAT'] || 'true'}"
     index_name "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_INDEX_NAME_INGRESS'] || 'ingress-controller'}"
     type_name "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_TYPE_NAME'] || '_doc'}"
     include_timestamp "#{ENV['FLUENT_ELASTICSEARCH_INCLUDE_TIMESTAMP'] || 'false'}"
     utc_index 'true'
     template_name "#{ENV['FLUENT_ELASTICSEARCH_TEMPLATE_NAME'] || use_nil}"
     template_file "#{ENV['FLUENT_ELASTICSEARCH_TEMPLATE_FILE'] || use_nil}"
     template_overwrite "#{ENV['FLUENT_ELASTICSEARCH_TEMPLATE_OVERWRITE'] || use_default}"
     sniffer_class_name "#{ENV['FLUENT_SNIFFER_CLASS_NAME'] || 'Fluent::Plugin::ElasticsearchSimpleSniffer'}"
     request_timeout "#{ENV['FLUENT_ELASTICSEARCH_REQUEST_TIMEOUT'] || '5s'}"
     <buffer>
       @type "file"
       path "/buffers/fluentd.ingress-controller.*.buffer"
       flush_thread_count "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_THREAD_COUNT'] || '8'}"
       flush_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_FLUSH_INTERVAL'] || '10s'}"
       chunk_limit_size "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_CHUNK_LIMIT_SIZE'] || '2M'}"
       queue_limit_length "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_QUEUE_LIMIT_LENGTH'] || '32'}"
       retry_max_interval "#{ENV['FLUENT_ELASTICSEARCH_BUFFER_RETRY_MAX_INTERVAL'] || '30'}"
       retry_forever true
       overflow_action block
     </buffer>
  </store>
</match>